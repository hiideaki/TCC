{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tests with Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from glob import glob\n",
    "import unidecode\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle as pkl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "      <th>TITLE_CLEAN</th>\n",
       "      <th>TEXT_LEN_CHAR</th>\n",
       "      <th>TEXT_LEN_TOKEN</th>\n",
       "      <th>TITLE_LEN_CHAR</th>\n",
       "      <th>TITLE_LEN_TOKEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>vamos assinar peticao cassacao mandato bolsona...</td>\n",
       "      <td>peticao impeachment bolsonaro precisa milhoes ...</td>\n",
       "      <td>328</td>\n",
       "      <td>36</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/08/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>lula vitima golpe politico merece estar preso ...</td>\n",
       "      <td>peticao lula livre contribui liberdade preside...</td>\n",
       "      <td>242</td>\n",
       "      <td>30</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>professor contou dilma matou mario kozel filho...</td>\n",
       "      <td>mario kozel filho assassinado dilma tiros</td>\n",
       "      <td>170</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>vergonha presidente oab mentiu pai morto milit...</td>\n",
       "      <td>felipe santa cruz presidente oab mentiu sobre ...</td>\n",
       "      <td>158</td>\n",
       "      <td>25</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/08/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>partido diabolico bandidos abrindo buracos est...</td>\n",
       "      <td>esquerda abrindo buracos estradas nordeste con...</td>\n",
       "      <td>155</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  y                                                  X  \\\n",
       "0  03/08/2019  1  vamos assinar peticao cassacao mandato bolsona...   \n",
       "1  04/08/2019  1  lula vitima golpe politico merece estar preso ...   \n",
       "2  05/08/2019  1  professor contou dilma matou mario kozel filho...   \n",
       "3  03/08/2019  1  vergonha presidente oab mentiu pai morto milit...   \n",
       "4  06/08/2019  1  partido diabolico bandidos abrindo buracos est...   \n",
       "\n",
       "                                         TITLE_CLEAN  TEXT_LEN_CHAR  \\\n",
       "0  peticao impeachment bolsonaro precisa milhoes ...            328   \n",
       "1  peticao lula livre contribui liberdade preside...            242   \n",
       "2          mario kozel filho assassinado dilma tiros            170   \n",
       "3  felipe santa cruz presidente oab mentiu sobre ...            158   \n",
       "4  esquerda abrindo buracos estradas nordeste con...            155   \n",
       "\n",
       "   TEXT_LEN_TOKEN  TITLE_LEN_CHAR  TITLE_LEN_TOKEN  \n",
       "0              36              81                9  \n",
       "1              30              54                7  \n",
       "2              24              41                6  \n",
       "3              25              82               13  \n",
       "4              19              59                7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../'\n",
    "\n",
    "PROCESSED_DATA_PATH = os.path.join(PATH, 'data/processed/')\n",
    "\n",
    "DF_FAKE_PATH = os.path.join(PROCESSED_DATA_PATH, 'df_fake_clean.pkl')\n",
    "DF_LEGIT_PATH = os.path.join(PROCESSED_DATA_PATH, 'df_legit_clean.pkl')\n",
    "\n",
    "df_fake = pkl.load(open(DF_FAKE_PATH, 'rb'))\n",
    "\n",
    "df_legit = pkl.load(open(DF_LEGIT_PATH, 'rb'))\n",
    "\n",
    "df = pd.concat((df_fake, df_legit), axis=0)\n",
    "\n",
    "df.rename({'TEXT_CLEAN': 'X', 'FAKE': 'y'}, axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16950, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining terms that are commonly found together\n",
    "\n",
    "e.g.: belo_horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [text.split() for text in df['X']]\n",
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_phrased'] = [phrases[s] for s in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(df['X_phrased'],\n",
    "                    min_count=5,\n",
    "                    window=9,\n",
    "                    size=100,\n",
    "                    workers=3,\n",
    "                    iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd = 'bolsonaro'\n",
    "print(\"Palavra: {}\".format(wrd))\n",
    "print(\"Palavras semelhantes:\")\n",
    "if wrd in w2v_model:\n",
    "    for item in w2v_model.wv.most_similar(wrd):\n",
    "        print('- {}'.format(item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #ff3333; font-weight: bold\">ATTENTION!</span> The cell below takes a long time to process!\n",
    "\n",
    "If file is already on disk, you can just load it on the other cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.DataFrame()\n",
    "\n",
    "# for text in tqdm_notebook(df['X_phrased']):\n",
    "#     aux = pd.DataFrame()\n",
    "#     for word in text:\n",
    "#         try:\n",
    "#             word_vec = w2v_model[word]\n",
    "#             aux = aux.append(pd.Series(word_vec), ignore_index=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         doc_vec = aux.mean()\n",
    "#     all_df = all_df.append(doc_vec, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(all_df, open('../data/processed/text_w2v.pkl', 'wb'))\n",
    "\n",
    "all_df = pkl.load(open('../data/processed/text_w2v.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(all_df, df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   22.6s remaining:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   22.8s remaining:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.3s finished\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(RandomForestClassifier(n_estimators=1000, n_jobs=-1), X_resampled, y_resampled, n_jobs=-1, cv=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94223108, 0.928     , 0.926     , 0.916     , 0.926     ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276462151394422"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled,\n",
    "                                                   y_resampled,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2001, 100), (501, 100), (2001,), (501,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       252\n",
      "           1       0.92      0.92      0.92       249\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       501\n",
      "   macro avg       0.92      0.92      0.92       501\n",
      "weighted avg       0.92      0.92      0.92       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[233  19]\n",
      " [ 21 228]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_resampled)\n",
    "print('PCA done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(columns = ['pca1','pca2'])\n",
    "\n",
    "df_pca['pca1'] = pca_result[:,0]\n",
    "df_pca['pca2'] = pca_result[:,1]\n",
    "\n",
    "print('Variance explained per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_scatter(x, colors):\n",
    "    # choose a color palette with seaborn.\n",
    "    num_classes = len(np.unique(colors))\n",
    "    palette = np.array(sns.color_palette([\"#c52f33\", \"#2A8DC7\"], num_classes))\n",
    "\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        # Position of each label at median of data points.\n",
    "\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24, color=\"#222222\", bbox=dict(facecolor='#eeeeee', alpha=0.8))\n",
    "#         txt.set_path_effects([\n",
    "#             PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "#             PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_scatter(df_pca.values, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "fashion_tsne = TSNE(random_state=42).fit_transform(X_resampled)\n",
    "\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_scatter(fashion_tsne, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
