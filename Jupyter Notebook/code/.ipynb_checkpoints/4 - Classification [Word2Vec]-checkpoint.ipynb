{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "from glob import glob\n",
    "import unidecode\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "      <th>TITLE_CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26/04/2019</td>\n",
       "      <td>True</td>\n",
       "      <td>comica nojenta cena aconteceu ultima terca fei...</td>\n",
       "      <td>maria rosario perde dentadura durante votacao ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22/04/2019</td>\n",
       "      <td>True</td>\n",
       "      <td>finalmente professoraheleypresente reuniao min...</td>\n",
       "      <td>bolsonaro condecorou professora heley abreu he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24/04/2019</td>\n",
       "      <td>True</td>\n",
       "      <td>audiencia ser grande hoje horario brasilia rec...</td>\n",
       "      <td>hoje record vai entrevistar bolsonaro minutos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25/04/2019</td>\n",
       "      <td>True</td>\n",
       "      <td>ibaneis rocha governador distrito federal fica...</td>\n",
       "      <td>ibaneis rocha governador viaja bebado vexame a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21/04/2019</td>\n",
       "      <td>True</td>\n",
       "      <td>mandou dinheiro narcotrafico rio farc sequestr...</td>\n",
       "      <td>marcelo odebrecht diz governo deu dinheiro tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE     y                                                  X  \\\n",
       "0  26/04/2019  True  comica nojenta cena aconteceu ultima terca fei...   \n",
       "1  22/04/2019  True  finalmente professoraheleypresente reuniao min...   \n",
       "2  24/04/2019  True  audiencia ser grande hoje horario brasilia rec...   \n",
       "3  25/04/2019  True  ibaneis rocha governador distrito federal fica...   \n",
       "4  21/04/2019  True  mandou dinheiro narcotrafico rio farc sequestr...   \n",
       "\n",
       "                                         TITLE_CLEAN  \n",
       "0  maria rosario perde dentadura durante votacao ...  \n",
       "1  bolsonaro condecorou professora heley abreu he...  \n",
       "2      hoje record vai entrevistar bolsonaro minutos  \n",
       "3  ibaneis rocha governador viaja bebado vexame a...  \n",
       "4  marcelo odebrecht diz governo deu dinheiro tra...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../'\n",
    "\n",
    "PROCESSED_DATA_PATH = os.path.join(PATH, 'data/processed/')\n",
    "\n",
    "DF_FAKE_PATH = glob(PROCESSED_DATA_PATH + '*')[0]\n",
    "DF_LEGIT_PATH = glob(PROCESSED_DATA_PATH + '*')[1]\n",
    "\n",
    "df_fake = pkl.load(open(DF_FAKE_PATH, 'rb'))\n",
    "\n",
    "df_legit = pkl.load(open(DF_LEGIT_PATH, 'rb'))\n",
    "\n",
    "df = pd.concat((df_fake, df_legit), axis=0)\n",
    "\n",
    "df.rename({'TEXT_CLEAN': 'X', 'FAKE': 'y'}, axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16858, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join terms that are commonly found together\n",
    "\n",
    "e.g.: belo_horizonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [text.split() for text in df['X']]\n",
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X_phrased'] = [phrases[s] for s in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(df['X_phrased'],\n",
    "                    min_count=5,\n",
    "                    window=5,\n",
    "                    size=50,\n",
    "                    workers=3,\n",
    "                    iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hidea\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('costas', 0.6767449975013733)\n",
      "('pingo', 0.6324369311332703)\n",
      "('mostras', 0.6280494928359985)\n",
      "('colera', 0.6240888237953186)\n",
      "('gargalhadas', 0.6114755868911743)\n",
      "('despertava', 0.6088407039642334)\n",
      "('ameacadora', 0.6035948991775513)\n",
      "('impulso', 0.6003566980361938)\n",
      "('transbordante', 0.6000973582267761)\n",
      "('entusiasmo', 0.600044310092926)\n"
     ]
    }
   ],
   "source": [
    "wrd = 'asas'\n",
    "print(wrd)\n",
    "if wrd in w2v_model:\n",
    "    for item in w2v_model.wv.most_similar(wrd):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5b80a013c6497bb782e2c4c5348140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16858), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hidea\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.DataFrame()\n",
    "\n",
    "for text in tqdm_notebook(df['X_phrased']):\n",
    "    aux = pd.DataFrame()\n",
    "    for word in text:\n",
    "        try:\n",
    "            word_vec = w2v_model[word]\n",
    "            aux = aux.append(pd.Series(word_vec), ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "        doc_vec = aux.mean()\n",
    "    all_df = all_df.append(doc_vec, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(all_df, open('../data/text_w2v.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(all_df,\n",
    "                                                   df['y'],\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13486, 50), (3372, 50), (13486,), (3372,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9730130486358244"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=800, random_state = 1)\n",
    "model.fit(train_x, train_y)\n",
    "test_pred = model.predict(test_x)\n",
    "accuracy_score(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99      3139\n",
      "        True       0.85      0.73      0.79       233\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3372\n",
      "   macro avg       0.92      0.86      0.89      3372\n",
      "weighted avg       0.97      0.97      0.97      3372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
