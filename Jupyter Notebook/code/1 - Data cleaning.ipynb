{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "In this notebook the JSONs extracted by the crawlers are loaded and normalized:\n",
    " - Dates are changed to the format **dd/mm/yyyy**\n",
    " - Texts are cleaned (removing non-alphabetic characters, lowering the case, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle as pkl\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from unidecode import unidecode\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../'\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(PATH, 'data/raw/')\n",
    "\n",
    "BOATOS_PATH = glob(RAW_DATA_PATH + '*')[0]\n",
    "ELPAIS_PATH = glob(RAW_DATA_PATH + '*')[1]\n",
    "G1_PATH = glob(RAW_DATA_PATH + '*')[2]\n",
    "\n",
    "OUTPUT_PATH = os.path.join(PATH, 'data/processed/')\n",
    "\n",
    "STOPWORDS = set(unidecode(sw) for sw in stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making FAKE NEWS DataFrame\n",
    "### Loading JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BOATOS_PATH, 'r') as f:\n",
    "    boatos = json.load(f)\n",
    "    \n",
    "for i, item in enumerate(boatos):\n",
    "    boatos[i]['text'] = ' '.join(item['text'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>FAKE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>Vamos assinar essa petição pela cassação do ma...</td>\n",
       "      <td>\\nPetição para o impeachment de Bolsonaro prec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/08/2019</td>\n",
       "      <td>Lula foi vítima de um golpe político e não mer...</td>\n",
       "      <td>\\nPetição Lula Livre contribui para liberdade ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Seu professor já te contou que a Dilma me mato...</td>\n",
       "      <td>\\nMario Kozel Filho foi assassinado por Dilma ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/08/2019</td>\n",
       "      <td>VERGONHA PRESIDENTE DA OAB MENTIU QUE O PAI FO...</td>\n",
       "      <td>\\nFelipe Santa Cruz, presidente da OAB, mentiu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/08/2019</td>\n",
       "      <td>Partido DIABÓLICO!! Bandidos do PT estão abrin...</td>\n",
       "      <td>\\nPT e esquerda estão abrindo buracos em estra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE                                               TEXT  \\\n",
       "0  03/08/2019  Vamos assinar essa petição pela cassação do ma...   \n",
       "1  04/08/2019  Lula foi vítima de um golpe político e não mer...   \n",
       "2  05/08/2019  Seu professor já te contou que a Dilma me mato...   \n",
       "3  03/08/2019  VERGONHA PRESIDENTE DA OAB MENTIU QUE O PAI FO...   \n",
       "4  06/08/2019  Partido DIABÓLICO!! Bandidos do PT estão abrin...   \n",
       "\n",
       "                                               TITLE  FAKE  \n",
       "0  \\nPetição para o impeachment de Bolsonaro prec...     1  \n",
       "1  \\nPetição Lula Livre contribui para liberdade ...     1  \n",
       "2  \\nMario Kozel Filho foi assassinado por Dilma ...     1  \n",
       "3  \\nFelipe Santa Cruz, presidente da OAB, mentiu...     1  \n",
       "4  \\nPT e esquerda estão abrindo buracos em estra...     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = pd.DataFrame(boatos)\n",
    "df_fake['FAKE'] = 1\n",
    "df_fake.rename({'date': 'DATE', 'text': 'TEXT', 'title': 'TITLE'}, axis=1, inplace=True)\n",
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making LEGIT NEWS DataFrame\n",
    "### Loading JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(G1_PATH, 'r') as f:\n",
    "    g1 = json.load(f)\n",
    "    \n",
    "for i, item in enumerate(g1):\n",
    "    g1[i]['text'] = ' '.join(item['text'])\n",
    "\n",
    "with open(ELPAIS_PATH, 'r') as f:\n",
    "    elpais = json.load(f)\n",
    "\n",
    "for i, item in enumerate(elpais):\n",
    "    elpais[i]['text'] = ' '.join(item['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing El Pais dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    'JAN': '01',\n",
    "    'FEV': '02',\n",
    "    'MAR': '03',\n",
    "    'ABR': '04',\n",
    "    'MAI': '05',\n",
    "    'JUN': '06',\n",
    "    'JUL': '07',\n",
    "    'AGO': '08',\n",
    "    'SET': '09',\n",
    "    'SEP': '09',\n",
    "    'OUT': '10',\n",
    "    'NOV': '11',\n",
    "    'DEZ': '12'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(elpais):\n",
    "    # Searching for dd/mmm/yyyy in the string\n",
    "    matched = re.findall(r'\\d+\\s+[a-zA-Z]+\\s+\\d+', item['date'].strip())\n",
    "    \n",
    "    # If did not find anything, continues onto the next iteration\n",
    "    if len(matched) == 0:\n",
    "        continue\n",
    "    \n",
    "    date = matched[0]\n",
    "    day = re.findall(r'\\d+', date)[0]\n",
    "    # Changing one digit days to two digits (e.g. 1/12/1999 to 01/12/1999)\n",
    "    if len(day) == 1:\n",
    "        date = date.replace(day + ' ', '0' + day + ' ')\n",
    "    date = re.sub(r'\\s+', ' ', date)\n",
    "    date = re.sub(r'\\s', '/', date)\n",
    "    \n",
    "    # Changing written month names to its numeric equivalent\n",
    "    month = re.findall('[a-zA-Z]+', date)[0]\n",
    "    if month in month_dict:\n",
    "        date = re.sub(month, month_dict[month], date)\n",
    "    \n",
    "    elpais[i]['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing registers dated before 2013\n",
    "for i, item in enumerate(elpais):\n",
    "    if int(item['date'].split('/')[2]) < 2013:\n",
    "        del elpais[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dias:  31\n",
      "Meses 12\n",
      "Anos: 7 - {'2017', '2019', '2018', '2016', '2015', '2013', '2014'}\n"
     ]
    }
   ],
   "source": [
    "# Making sure the dates make sense\n",
    "day = set()\n",
    "month = set()\n",
    "year = set()\n",
    "\n",
    "for item in elpais:\n",
    "    date = re.findall('\\d+', item['date'])\n",
    "    day.add(date[0])\n",
    "    month.add(date[1])\n",
    "    year.add(date[2])\n",
    "    \n",
    "print('Dias: ',len(day))\n",
    "print('Meses', len(month))\n",
    "print('Anos:', len(year), '-', year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing G1 dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(g1):\n",
    "    matched = re.findall('\\d+/\\d+/\\d+', g1[5]['date'].strip())\n",
    "    if len(matched) == 0:\n",
    "        continue\n",
    "    g1[i]['date'] = matched[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>FAKE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/06/2019</td>\n",
       "      <td>O atual mandato presidencial no Brasil começou...</td>\n",
       "      <td>Começam a soar os alarmes sobre a sustentabili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/06/2019</td>\n",
       "      <td>Poucas horas antes de milhares de  manifestant...</td>\n",
       "      <td>Corte ou contingenciamento, quem está certo na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/06/2019</td>\n",
       "      <td>Se o tamanho de uma figura pública se mede pel...</td>\n",
       "      <td>Trump insulta prefeito de Londres no início de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26/05/2019</td>\n",
       "      <td>Um dos tantos fenômenos imparáveis trazidos pe...</td>\n",
       "      <td>O líder e eu (e ninguém no meio)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/06/2019</td>\n",
       "      <td>Após semanas de audiências públicas, o projeto...</td>\n",
       "      <td>A reforma da Previdência pesará mais sobre os ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE                                               TEXT  \\\n",
       "0  04/06/2019  O atual mandato presidencial no Brasil começou...   \n",
       "1  02/06/2019  Poucas horas antes de milhares de  manifestant...   \n",
       "2  03/06/2019  Se o tamanho de uma figura pública se mede pel...   \n",
       "3  26/05/2019  Um dos tantos fenômenos imparáveis trazidos pe...   \n",
       "4  03/06/2019  Após semanas de audiências públicas, o projeto...   \n",
       "\n",
       "                                               TITLE  FAKE  \n",
       "0  Começam a soar os alarmes sobre a sustentabili...     0  \n",
       "1  Corte ou contingenciamento, quem está certo na...     0  \n",
       "2  Trump insulta prefeito de Londres no início de...     0  \n",
       "3                   O líder e eu (e ninguém no meio)     0  \n",
       "4  A reforma da Previdência pesará mais sobre os ...     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_news = elpais[:]\n",
    "legit_news.extend(g1)\n",
    "\n",
    "df_legit = pd.DataFrame(legit_news)\n",
    "df_legit['FAKE'] = 0\n",
    "df_legit.rename({'date': 'DATE', 'text': 'TEXT', 'title': 'TITLE'}, axis=1, inplace=True)\n",
    "df_legit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Making sure we're dealing with strings and lowering the characters\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Stripping accents\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # Removing characters that aren't alphabetic\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    \n",
    "    # Removing extra spaces\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    # Removing words with length equal or lower than 2\n",
    "    return ' '.join([token for token in text.split() if len(token) > 2 and token not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and dumping Fake News DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.loc[df_fake['TEXT'].apply(len) == 0, ['TEXT']] = df_fake[df_fake['TEXT'].apply(len) == 0]['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake['TEXT_CLEAN'] = df_fake['TEXT'].apply(clean_text)\n",
    "df_fake['TITLE_CLEAN'] = df_fake['TITLE'].apply(clean_text).apply(lambda x: re.sub('boato(|s)', '', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.drop(['TEXT', 'TITLE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(df_fake, open(os.path.join(OUTPUT_PATH, 'df_fake_clean.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and dumping Legit News Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legit = df_legit[df_legit['TEXT'].apply(len) > 0]\n",
    "df_legit['TEXT_CLEAN'] = df_legit['TEXT'].apply(clean_text)\n",
    "df_legit['TITLE_CLEAN'] = df_legit['TITLE'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legit.drop(['TEXT', 'TITLE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(df_legit, open(os.path.join(OUTPUT_PATH, 'df_legit_clean.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
