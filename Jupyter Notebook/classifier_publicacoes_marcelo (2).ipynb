{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38177, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/BASE_ANALITICA.xlsx')\n",
    "\n",
    "df = df[df['Resultado Sem Providência Publicação Gracco'] != 'Não Localizado']\n",
    "\n",
    "df = df[['Resultado Sem Providência Publicação Gracco', 'Região', 'Memo do Andamento']]\n",
    "\n",
    "df['Memo do Andamento'] = [str(s) for s in df['Memo do Andamento']]\n",
    "\n",
    "# df['Resultado Sem Providência Publicação Gracco'] = [0 if res == 'NÃO' else 1 for res in df['Resultado Sem Providência Publicação Gracco']]\n",
    "\n",
    "df['Memo do Andamento'] = [re.sub(r'(sem provid[eê]ncias|SEM PROVID[EÊ]NCIAS)', '', sent) for sent in df['Memo do Andamento']]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 17539, 1: 20638})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(df['Resultado Sem Providência Publicação Gracco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20518, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Memo do Andamento'].str.contains('SEM PROVIDÊNCIAS')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Memo do Andamento'].str.contains('SEM PROVIDENCIAS')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_spacy(frase):\n",
    "    frase = str(frase)\n",
    "    frase = re.sub(r'\\s+', ' ', frase)\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_spacy(frase):\n",
    "    frase = str(frase)\n",
    "    frase = frase.lower()\n",
    "    frase = re.sub(r'¹|²|³|º|ª', '', frase)\n",
    "    frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "    frase = re.sub(r'[^\\w\\s]|\\d', '', frase)\n",
    "    frase = re.sub(r'\\s+', ' ', frase)\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_frase_spacy(frase):\n",
    "    doc = spacy_nlp(frase)\n",
    "    temp = [(token.orth_, token.pos_) for token in doc if token.pos_ not in ['PROPN']]\n",
    "    \n",
    "    concat = ''\n",
    "    for par in temp:\n",
    "        item = pos_spacy(par[0])\n",
    "        if(len(item) > 2):\n",
    "            concat += item + \" \"\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intimação para exequentes distribuidora cep deodoro cep dados junho junho cumprimento dias metropolitana curitiba processual distribuidora módulo cep deodoro cep determina quando ante defiro desde por oportunamente arquivemse publiquese nlls digitalmente por extinta arq '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['Memo do Andamento'] = df['Memo do Andamento'].apply(pre_spacy)\n",
    "limpar_frase_spacy(pre_spacy(df['Memo do Andamento'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTIMAÇÃO ANEXADA NA ABA DE DOCUMENTOS. 2.0000455-2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Memo do Andamento'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_temp = pickle.load(open(\"clean_x.pkl\",'rb'))\n",
    "\n",
    "# x_temp = df['Memo do Andamento'].apply(pre_spacy)\n",
    "# x_temp = x_temp.apply(limpar_frase_spacy)\n",
    "# pickle.dump(x_temp, open(\"clean_x.pkl\",'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_string(frase):\n",
    "    frase = str(frase)\n",
    "    frase = frase.lower()\n",
    "    frase = re.sub(r'(sem provid[eê]ncias)', '', frase)\n",
    "    frase = re.sub(r'<\\w+>|\\(\\w+\\)|-\\w+|[^\\w\\s]|\\d|¹|²|³|º|ª', '', frase)\n",
    "    frase = re.sub(r'\\s+', ' ', frase)\n",
    "    frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp = df['Memo do Andamento'].apply(limpar_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_tokenizer(incoming_string):\n",
    "    # removing some line endings\n",
    "    incoming_string = incoming_string.replace('\\r', '')\n",
    "    incoming_string = incoming_string.replace('\\n', '')\n",
    "    # tokenizing string\n",
    "    doc_spacy = spacy_nlp(incoming_string)\n",
    "    # making the lemmatization of the tokenized string (ignoring puntuations and words from the stopwords list)\n",
    "    return [token.lemma_ for token in doc_spacy if not ((token.is_punct) or (token.is_space))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_temp = pickle.load(open(\"clean_x_adv.pkl\",'rb'))\n",
    "\n",
    "# x_temp = df['Memo do Andamento'].apply(adv_tokenizer)\n",
    "# pickle.dump(x_temp, open(\"clean_x_adv.pkl\",'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['janeiro', 'fevereiro', 'marco', 'março', 'abril', 'junho', 'julho', 'agosto', \n",
    "                    'setembro', 'outubro', 'novembro', 'dezembro', 'segunda', 'terca', 'terça', \n",
    "                    'quarta', 'quinta', 'sexta', 'sabado', 'sábado', 'domingo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Região\n",
       "Centro-Oeste    2346.0\n",
       "Nordeste        2004.0\n",
       "Norte           2353.0\n",
       "Sudeste         1170.0\n",
       "Sul             1949.0\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df['Memo do Andamento'].apply(str).apply(len)\n",
    "df.groupby('Região').mean().round()['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257.65460879587187\n"
     ]
    }
   ],
   "source": [
    "print(x_temp.apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resultado Sem Providência Publicação Gracco</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.110935e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.884553e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   length\n",
       "Resultado Sem Providência Publicação Gracco              \n",
       "0                                            1.110935e+07\n",
       "1                                            3.884553e+06"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Resultado Sem Providência Publicação Gracco').var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import RSLPStemmer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn import utils\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_temp = df['Memo do Andamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_temp, df['Resultado Sem Providência Publicação Gracco'], test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect = TfidfVectorizer(strip_accents='unicode', stop_words=custom_stopwords)\n",
    "vect = TfidfVectorizer(strip_accents='unicode', ngram_range=(1, 3),  min_df=0.2, max_df=0.8, stop_words=custom_stopwords)\n",
    "        \n",
    "\n",
    "clust = KMeans(n_clusters=3)\n",
    "\n",
    "# clf = XGBClassifier(n_jobs=-1, n_estimators=100)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "# clf = LogisticRegression()\n",
    "# clf = SVC(gamma='scale', probability=False)\n",
    "# clf = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "# clf = SGDClassifier(epsilon=0.01)\n",
    "\n",
    "\n",
    "text_pipe = Pipeline([('vect', vect), ('clust', clust), ('clf', clf)])\n",
    "# text_pipe = Pipeline([('vect', vect), ('clf', clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.79812909, 0.79831618, 0.795884  , 0.79509731, 0.79079341])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(strip_accents='unicode', ngram_range=(1, 3),  min_df=0.2, max_df=0.8, stop_words=custom_stopwords)\n",
    "clust = KMeans(n_clusters=3)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cv = cross_val_score(text_pipe, x_train, y_train, cv=5, verbose=1, n_jobs=-1)\n",
    "# cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34034    \\r\\n\\r\\nDATA DE DISPONIBILIZACAO DA PUBLICACAO...\n",
       "33127    \\r\\n\\r\\n1º JUIZADO ESPECIAL CÍVEL E CRIMINAL\\r...\n",
       "24967    LIDA EM: 12/06/2018. \\r\\n\\r\\n» DADOS DO PROCES...\n",
       "29047    \\r\\nTURIAÇU\\r\\nDATA DE DISPONIBILIZACAO DA PUB...\n",
       "22129     - PRAZOS JÁ AGENDADOS.\\r\\n\\r\\nVARA ESPECIALIZ...\n",
       "Name: Memo do Andamento, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ccade40ff3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext_pipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vect' is not defined"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "text_pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "\n",
    "\n",
    "cv = cross_val_score(text_pipe, x_train, y_train, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348240072707718"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564905642410221"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82918616, 0.83610851, 0.82993452, 0.84206587, 0.84281437])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "text_pipe = Pipeline([('vect', vect), ('clf', clf)])\n",
    "\n",
    "\n",
    "cv = cross_val_score(text_pipe, x_train, y_train, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360218851352487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcelo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=0.2,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = text_pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.44      0.53      5281\n",
      "           1       0.63      0.81      0.71      6173\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     11454\n",
      "   macro avg       0.64      0.62      0.62     11454\n",
      "weighted avg       0.64      0.64      0.62     11454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2326 2955]\n",
      " [1192 4981]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NÃO       0.99      0.99      0.99      5281\n",
      "         SIM       0.99      0.99      0.99      6173\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     11454\n",
      "   macro avg       0.99      0.99      0.99     11454\n",
      "weighted avg       0.99      0.99      0.99     11454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5204   31]\n",
      " [  77 6142]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
